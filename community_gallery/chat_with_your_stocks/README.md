# Stock Market Analysis with Preswald

## Overview

This project leverages the Preswald library to perform an Exploratory Data Analysis (EDA) on two specific datasets: Amazon stock data from 1997 to February 2025, and Tesla stock data from 2015 to 2024. The application allows users to select which dataset to analyze and provides an automatic EDA, including visualizations and insights.


The application allows users to choose which dataset to analyze. It automatically generates visualizations and insights, making it easy to explore complex financial data.

A standout feature is the **Chat with Your Stock** functionality. This interactive component enables users to ask questions in natural language about the selected dataset. Hereâ€™s how it works:
- The DataFrame is converted into a Duck DB database using Preswald.
- Chains and agents are then created to translate natural language queries into SQL.
- The generated SQL queries are executed against Duck DB.
- The results are sent to a GPT-4o mini model, which processes the context and returns a clear, natural language answer.

This architecture not only supports in-depth EDA but also makes it easy to integrate additional datasets for scalable analysis.

## Features

- **Automatic EDA:**  
  Generate comprehensive exploratory data analysis for Amazon and Tesla stock datasets with just a few clicks.

- **Natural Language Querying:**  
  Ask questions in everyday language and receive insights generated by converting your query into SQL. The system uses chains and agents to handle the translation process and execute queries on a Duck DB database.

- **Interactive Visualizations:**  
  Leverage Plotly to automatically generate dynamic and interactive visualizations that help you quickly understand trends and patterns.

- **Scalable Analysis:**  
  The code is designed to be dataset-agnostic, allowing you to analyze any dataset by following simple configuration steps.

## Built With

- **Preswald:**  
  For building interactive data applications and managing the EDA and natural language query pipelines.
  
- **OpenAI GPT-4o mini:**  
  For natural language processing and generating responses based on the context retrieved from Duck DB.
  
- **Plotly:**  
  For creating interactive visualizations that dynamically present analysis results.
  
- **Pandas:**  
  For data manipulation, cleaning, and transformation.
  
- **Duck DB Integration:**  
  Converts DataFrames into a database format to enable SQL querying driven by natural language inputs.

## How It Works

1. **Data Processing & EDA Generation:**  
   The project automatically processes the input datasets to produce visualizations and key insights. This is achieved by using Pandas for data manipulation and Plotly for rendering visualizations.

2. **Natural Language Querying Pipeline:**  
   - **Conversion to Duck DB:**  
     The DataFrame is converted into a Duck DB database, providing a structured format for querying.
   - **Chain & Agent Mechanism:**  
     Using langchain and OpenAI, the project creates chains and agents that translate natural language queries into SQL statements.
   - **Query Execution & Response Generation:**  
     The generated SQL is executed against Duck DB. The results are then passed to GPT-4o mini, which processes the context and responds in natural language, making the insights easily accessible.

## Getting Started

### Prerequisites

- Python 3.8 or higher
- Preswald library
- OpenAI API key


### Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/yourusername/your-repo.git
   cd your-repo/community_gallery/chat_with_your_stocks
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure your API keys**:
   - Add your OpenAI API key to `secrets.toml`.

### Configuration

1. **Configure your data connections in `preswald.toml`**:
   - To add more datasets, configure them like this:
     ```toml
     [data.tesla_stock_v2_csv]
     type = "csv"
     path = "data/tesla_stock_v2.csv"
     ```

2. **Add sensitive information (passwords, API keys) to `secrets.toml`**:
   - The `secrets.toml` should look like this:
     ```toml
     [api_keys]
     openai = "your-openai-api-key"

     [data.postgres]
     password = "your-database-password"
     ```

3. **Run your app**:
   ```bash
   preswald run hello.py
   ```

### Usage

- **Select Dataset**: Choose between Amazon or Tesla stock data for analysis.
- **Explore Data**: View automatic EDA results and visualizations.
- **Ask Questions**: Use the "Chat with Your Stock" feature to ask questions in natural language.

## Interesting Aspects

- **Versatile Analysis**: The code is designed to perform EDA and Natural Language on any dataset, not just the provided stock data. (Yo can add a dataset with the Configuration Step 1 , and adding this dataset in hello.py in lines 32-50 )
- **Natural Language Interface**: Users can interact with the data using natural language, thanks to the integration with OpenAI's GPT-4o mini.
- **Automatic Visualizations**: Visualizations are generated automatically, providing immediate insights.

## Contributing

Contributions are welcome! Please fork the repository and submit a pull request with your changes.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- Thanks to the developers of Preswald, OpenAI, Langchain and Plotly for their powerful tools and libraries.